<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title> &#187; reactive landscapes</title>
	<atom:link href="http://computationalspaces.org/projekte/reactive-landscapes/feed/" rel="self" type="application/rss+xml" />
	<link>http://computationalspaces.org</link>
	<description></description>
	<lastBuildDate>Mon, 07 Dec 2015 16:37:38 +0000</lastBuildDate>
	<language>de-DE</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=4.3.1</generator>
	<item>
		<title></title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Sat, 15 Jan 2011 06:24:40 +0000</pubDate>
		<dc:creator><![CDATA[csadmin]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=27</guid>
		<description><![CDATA[reactive landscapes – installationen immersive environments führen den besucher durch abstrakte landschaften ausstellungszeitraum: sa. 26.03. &#8211; 20:00 uhr so. 27.03. &#8211; 15:00 &#8211; 19:00 uhr austellungsort: frappant e.V., zeiseweg 9, 22765 hamburg ehemalige viktoriakaserne http://frappant.org Ein Kooperationsprojekt der Departments Design und Informatik mit Christine Böhler, Marc Breit, Hannes Dieck, Aleksej Dygoduk, Roman Geez, Julia Holtmann, Johannes [&#8230;]]]></description>
				<content:encoded><![CDATA[<div class="post">
<p>reactive landscapes – installationen</p>
<p>immersive environments führen den besucher durch<br />
abstrakte landschaften</p>
<p>ausstellungszeitraum:<br />
sa. 26.03. &#8211; 20:00 uhr</p>
<p>so. 27.03. &#8211; 15:00 &#8211; 19:00 uhr</p>
<p>austellungsort:<br />
frappant e.V., zeiseweg 9, 22765 hamburg ehemalige<br />
viktoriakaserne</p>
<p><a href="http://frappant.org">http://frappant.org </a></p>
<p><a href="../../../wp-content/uploads/reactive_landscapes_1.jpg"><img class="alignnone size-thumbnail wp-image-1446" title="reactive_landscapes_1" src="../../../wp-content/uploads/reactive_landscapes_1-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_2.jpg"><img class="alignnone size-thumbnail wp-image-1447" title="reactive_landscapes_2" src="../../../wp-content/uploads/reactive_landscapes_2-70x70.jpg" alt="" width="70" height="70" /> </a><a href="../../../wp-content/uploads/reactive_landscapes_9.jpg"><img class="alignnone size-thumbnail wp-image-1462" title="reactive_landscapes_9" src="../../../wp-content/uploads/reactive_landscapes_9-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_3.jpg"><img class="alignnone size-thumbnail wp-image-1448" title="reactive_landscapes_3" src="../../../wp-content/uploads/reactive_landscapes_3-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes.jpg"><img class="alignnone size-thumbnail wp-image-1492" title="reactive_landscapes" src="../../../wp-content/uploads/reactive_landscapes-70x70.jpg" alt="" width="70" height="70" /></a> <a href="http://computationalspaces.org/wp-content/uploads/reactive_landscapes_17.jpg"> </a><a href="../../../wp-content/uploads/reactive_landscapes_16.jpg"><img class="alignnone size-thumbnail wp-image-1488" title="reactive_landscapes_16" src="../../../wp-content/uploads/reactive_landscapes_16-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_4.jpg"><img class="alignnone size-thumbnail wp-image-1449" title="reactive_landscapes_4" src="../../../wp-content/uploads/reactive_landscapes_4-70x70.jpg" alt="" width="70" height="70" /> </a> <a href="../../../wp-content/uploads/reactive_landscapes_10.jpg"><img class="alignnone size-thumbnail wp-image-1480" title="reactive_landscapes_10" src="../../../wp-content/uploads/reactive_landscapes_10-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_19.jpg"><img class="alignnone size-thumbnail wp-image-1496" title="reactive_landscapes_19" src="../../../wp-content/uploads/reactive_landscapes_19-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_18.jpg"><img class="alignnone size-thumbnail wp-image-1494" title="reactive_landscapes_18" src="../../../wp-content/uploads/reactive_landscapes_18-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_14.jpg"><img class="alignnone size-thumbnail wp-image-1484" title="reactive_landscapes_14" src="../../../wp-content/uploads/reactive_landscapes_14-70x70.jpg" alt="" width="70" height="70" /></a> <a href="../../../wp-content/uploads/reactive_landscapes_151.jpg"><img class="alignnone size-thumbnail wp-image-1487" title="reactive_landscapes_15" src="../../../wp-content/uploads/reactive_landscapes_151-70x70.jpg" alt="" width="70" height="70" /></a> <a href="http://computationalspaces.org/wp-content/uploads/reactive_landscapes_15.jpg"> </a><a href="../../../wp-content/uploads/reactive_landscapes_7.jpg"><img class="alignnone size-thumbnail wp-image-1452" title="reactive_landscapes_7" src="../../../wp-content/uploads/reactive_landscapes_7-70x70.jpg" alt="" width="70" height="70" /></a></p>
</div>
<div class="video"><iframe src="http://player.vimeo.com/video/22619950?title=0&amp;byline=0" width="400" height="225" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<div class="namen">
<p>Ein Kooperationsprojekt der Departments Design und Informatik mit Christine Böhler, Marc Breit, Hannes Dieck, Aleksej Dygoduk, Roman Geez, Julia Holtmann, Johannes Knapp, Benjamin Kuska, Alexander Philipp, Milena Rötting, Janina Schlichte, Urte Schwass, Moritz Uhlig.</p>
<p>Gäste: Henna Atif, Anastasia Lichtenwald, Sanna Naser, Kiana Shahsaheby, Sonja Hormann.</p>
<p>Betreut von Prof. Franziska Hübler und Prof. Dr. Birgit Wendholt mit Unterstützung der Zentralwerkstatt.</p>
<p>Ausstellungsdokumentation: <a href="mailto:adriane_kuenne@gmx.net">Adriane Künne</a>.<br />
Projektvideos: <a href="http://www.marissa-illu.de/" target="_blank">Marissa Kimmel</a>.</p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>PixelCity…Lichtstadt im Wandel</title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Fri, 14 Jan 2011 13:41:17 +0000</pubDate>
		<dc:creator><![CDATA[pixelcity]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=685</guid>
		<description><![CDATA[von Janina Schlichte, Alex Philipp und Moritz Uhlig Design Aspekte Die Installation soll vom Aufbau der Konstruktion an &#8220;Straßen der Großstadt bei Nacht&#8221; erinnern. Die durch Bewegung der Betrachter erzeugten Lichtveränderungen symbolisieren den stetigen Veränderungsprozess in urbanen, öffentlichen und dicht besiedelten Räumen. Die Stadt ist ein Erlebnisraum und eine Bühne mit stetig wandelnden und individuellen [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>von Janina Schlichte, Alex Philipp und Moritz Uhlig</p>
<p><iframe src="http://player.vimeo.com/video/19486354" width="500" height="281" frameborder="0" title="PixelCity" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<h4>Design Aspekte</h4>
<p>Die Installation soll vom Aufbau der Konstruktion an &#8220;Straßen der Großstadt bei Nacht&#8221; erinnern. Die durch Bewegung der Betrachter erzeugten Lichtveränderungen symbolisieren den stetigen Veränderungsprozess in urbanen, öffentlichen und dicht besiedelten Räumen.</p>
<p>Die Stadt ist ein Erlebnisraum und eine Bühne mit stetig wandelnden und individuellen Strukturen. &#8220;Citytainment&#8221; ist das Stichwort, mit dem in der Thematik dieser Arbeit gespielt wird. Möglichst sensibel tasteten wir uns mit dem Einbau von Lichteffekten und Wahl der Farbkompositionen voran, die oftmals nochmals verworfen wurden, um für uns alle an ein zufriedenstellendes Ergebnis zu kommen. Die integrierte Projektion, die das Konzept visuell unterstützt wurde dem Thema angepasst, so verändern sich innerhalb ständig kleine Details. Unser Ziel ist es, sowohl eine poetisch-ästhetisch anmutende Arbeit zu präsentieren, wie auch einen kleinen Prototypen für die futuristische Lichtplanung im öffentlichen Raum.</p>
<p>Interessant zu beobachten, ist natürlich auch der Entwicklungsprozess der Kommunikation zwischen Mensch und Technik. Das Thema &#8221; Überwachung&#8221; bleibt bei realen Aufbau von Installationen in der Großstadt natürlich nicht aus. Doch da der Großteil der öffentlichen Räume ja eh schon bewacht wird, könnte man an diesen Stellen doch für eine hübschere und unbedrohlichere Hülle sorgen…?</p>
<p><img class="alignnone size-full wp-image-1043" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/PixelCity1.jpg" alt="" width="400" height="267" /></p>
<h4>Technik</h4>
<h4>Hardware</h4>
<p>Das Hauptprogramm läuft auf einem gewöhnlichen Rechner, an den ein Arduino Mikrocontroller und eine Kamer angeschlossen sind. Zusätzlich kommen drei kaskadierte <a href="http://www.brilldea.com/product_LEDPainter.html">LED-Treiberboards</a> zum Einsatz, die jeweils über drei 16-Kanal Treiberbausteine verfügen. Somit ist es möglich 48 RGB-LED-Einheiten anzusteuern.</p>
<p><img class="alignnone size-full wp-image-1044" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/PixelCity2.jpg" alt="" width="400" height="267" /></p>
<h4>Software</h4>
<p>Die Interaktion mit der Kamera ist mittels einer in C++ geschriebenen Komponente realisiert, die OpenCV-Blibliothek zur Bildverarbeitung nutzt. Es werden Haar Cascades zur Objekterkennung verwendet, mit denen man durch unterschiedliche Trainingsdateien beispielsweise Körper, Oberkörper oder Gesichter erkennen und deren Position im Raum bestimmen kann.</p>
<p>Da die Objekterkennung stark von guten Lichtverhältnissen abhängt und je nach zu erkennedem Objekt bzw. Körperteil eine aufwändig zu erstellende Trainingsdatei benötigt wird kann alternativ auch ein einfacherer Differenzbildalgorithmus verwendet werden, der lediglich auf Bildänderungen &#8211; also Bewegungen &#8211; reagiert.</p>
<p>Die Koordinaten der erkannten Objekte werden dann in einem anderen Programmteil weiterverarbeitet: aus deren Position und Größe wird eine entsprechende Ausgabe an die LED-Treiber erzeugt. Dieser Programmteil ist in Scala geschrieben. Ebenso in Scala implementiert ist die Projektion, die aber die Eingabedaten der Kamera nicht verwendet.</p>
<p>Die Kommunikation zu den Treiberboards erfolgt über den Arduino. Dieser wird über den USB-Anschluss des Rechners mit Daten versorgt. Auf dem Arduino selbst läuft ein einfaches Programm, das lediglich den Eingabestrom synchronisiert und die vom PC übertragenen RGB-Werte unverändert in die Treiberbausteine schreibt.</p>
<p>Anfangs war der gesamte Code in Java bzw. Scala geschrieben und nutzte die OpenCV-Einbindung des Processing-Frameworks. Diese Einbindung ist jedoch sehr allgemein gehalten und die kompletten Bilddaten werden umkopiert um sie im Javateil des Programmes zu verwenden. Zudem wird jedes erfasste Bild in ein anderes Format umgewandelt, was zusätzliche Rechenzeit benötigt. Da wir die Rohbilddaten jedoch nicht benötigen, haben wir uns entschlossen den Bildverarbeitungsteil in C++ zu implementieren und lediglich die benötigten Koordinaten der Objekte im restlichen Code nutzbar zu machen. Dies erhöht die Anzahl der Bilder, die pro Zeiteinheit verarbeitet werden können leicht &#8211; jedoch nicht so stark wie angenommen, da die Auswertung der Haar Cascades die meiste Rechenzeit in Anspruch nimmt.</p>
<p>Zur Visualisierung der Kameradaten werden die Lichtkästen in Gruppen aufgeteilt und diesen Gruppen Koordinaten und eine Farbe zugeordnet. Wird nun ein einem Bereich des Kamerabildes Bewegung oder ein Objekt erkannt, so lässt das Programm die Gruppen aufleuchten, die diesem Bereich zugeordnet sind.</p>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>led land</title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Fri, 14 Jan 2011 13:41:05 +0000</pubDate>
		<dc:creator><![CDATA[landscape]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=682</guid>
		<description><![CDATA[von Benjamin Kuska, Johannes Knapp und Christine Böhler Prototyp Der Prototyp stellt eine Qualle mit 3 Tentakeln dar. Design Technik Im Prototyp wurden sieben Lichtbereiche integriert. Der Körper bestand insgesamt aus vier Lichtbereichen, die sich am Design orientierten. Die drei Tentakeln stellten jeweils einen weiteren Bereich dar. Das Licht wurde durch LED-Stripes erzeugt. Die Steuerung [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>von Benjamin Kuska, Johannes Knapp und Christine Böhler</p>
<p><iframe src="http://player.vimeo.com/video/19483923" width="500" height="281" frameborder="0" title="led land" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<h4>Prototyp</h4>
<p>Der Prototyp stellt eine Qualle mit 3 Tentakeln dar.</p>
<h4>Design</h4>
<p><img class="alignnone size-full wp-image-1269" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/landscape_1.jpg" alt="" width="400" height="300" /></p>
<h4>Technik</h4>
<p>Im Prototyp wurden sieben Lichtbereiche integriert. Der Körper bestand insgesamt aus vier Lichtbereichen, die sich am Design orientierten. Die drei Tentakeln stellten jeweils einen weiteren Bereich dar.</p>
<p>Das Licht wurde durch LED-Stripes erzeugt. Die Steuerung verlief über einen Arduino mit angeschlossenem TLC. Die Interaktion wurde von eine Logitech Kamera aufgenommen.</p>
<p>Das Bild der Kamera wurde mit einem Raster aus vier Bereichen belegt. Mittels Differenzbilder wurde Bewegung in den Bereichen erkannt und die Kennnummer des entsprechenden Bereichs an den Arduino übertragen.</p>
<p><img class="alignnone size-full wp-image-1272" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/landscape_2.jpg" alt="" width="300" height="400" /></p>
<h4>Release</h4>
<p><img class="alignnone size-full wp-image-1027" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Landscape_Bild1.jpg" alt="" width="267" height="400" /></p>
<p>Das Release Objekt entfernte sich nun von dem Thema „Unterwasser“ hin zu „Entspannungswelt“. Es wurde ein Liegewiese erschaffen, die mit drei Sitzflächen, einem „Fluss“ und einem organischen Teil ausgestattet ist. Das gesamte Objekt nimmt eine Grundfläche von ca. 4m²  ein.</p>
<p><img class="alignnone size-full wp-image-1279" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/landscape_3.jpg" alt="" width="400" height="300" /></p>
<h4>Design</h4>
<p><img class="alignnone size-full wp-image-1028" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Landscape_Bild2.jpg" alt="" width="267" height="400" /></p>
<h4>Technik</h4>
<p>In der Liegewiese können die drei Sitzbereiche, fünf Abschnitte im Fluss und ein Teil im organischen Bereich separat angesteuert werden. Die Steuerung übernimmt hierbei ein Arduino mit zwei angeschlossenen TLCs.</p>
<p>Das Licht wurde durch LED-Stripes (à 3 LEDs) realisiert. In den Sitzbereichen sind jeweils 15 LED-Stripes. Im Fluss liegen je Abschnitt 9 LED-Stripes. Und im organischen Teil liegen 25 LED-Stripes. Insgesamt wurden somit 115 LED-Stripes verbaut.</p>
<p>Die Interaktion wurde durch eine Kamera über dem Objekt realisiert. Es wurde ein Raster über das Kamerabild gelegt, dass sowohl die drei Sitzbereiche, also auch die fünf Aktionsbereiche des Flusses überdecken. Der Kennnummer des jeweiligen Bereichs wurde dann an den Arduino übertragen.</p>
<p><img class="alignnone size-full wp-image-1029" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Landscape_Bild3.jpg" alt="" width="400" height="267" /></p>
<p>Auf dem Arduino mussten mehrere Prozesse parallel ablaufen. Die Prozesse sind</p>
<ul>
<li>die Atmung des organischen Bereichs durch ein pulsierendes Licht,</li>
<li>das fließende Wasser im Flussbett durch ein Lauflicht mit abklingender Welle</li>
<li>der Fadeeffekt im Sitzbereich und das verzögerte zurück faden in den Ausgangszustand des Sitzbereichs</li>
</ul>
<p>Um diese Parallelität zu realisieren wurde auf die Bibliothek „TimedAction“ <a href="index.html#_ftn1">[1]</a> gesetzt. Hierüber können die einzelnen Prozesse in der Loop der Arduino Anwendung auf einfache Weise aktiviert, geprüft und deaktiviert werden.</p>
<hr size="1" /><a name="_ftnref1">[1]</a> <a href="http://www.arduino.cc/playground/Code/TimedAction" target="_blank">http://www.arduino.cc/playground/Code/TimedAction</a></p>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Wave</title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Fri, 14 Jan 2011 13:40:47 +0000</pubDate>
		<dc:creator><![CDATA[wave]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=679</guid>
		<description><![CDATA[von Marc Breit, Milena Rötting und Julia Holtmann Design Aspekte Der ursprüngliche Anstoß für das interaktive Objekt „Marionette“ vormals „Wave“ war der Gedanke organische Formen oder skurrile Bewegungen, die man aus der Natur kennt, zu imitieren, ohne zu realistisch dabei zu werden. Hierbei war uns besonders wichtig, dass dem Betrachter seine aktive Rolle begreiflich wird, [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>von Marc Breit, Milena Rötting und Julia Holtmann</p>
<p><iframe src="http://player.vimeo.com/video/19480952" width="500" height="281" frameborder="0" title="Wave" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<h4>Design Aspekte</h4>
<p>Der ursprüngliche Anstoß für das interaktive Objekt „Marionette“ vormals „Wave“ war der Gedanke organische Formen oder skurrile Bewegungen, die man aus der Natur kennt, zu imitieren, ohne zu realistisch dabei zu werden. Hierbei war uns besonders wichtig, dass dem Betrachter seine aktive Rolle begreiflich wird, nämlich dass er Teil der Installation ist und aktiv den Zustand des Objektes beeinflusst.</p>
<p>Trotz der anfänglichen Begeisterung mit Licht eine andächtige alltagsferne Atmosphäre zu erzeugen, welche bereits in etlichen  Materialexperimenten auf ihre Wirkung erprobt worden war, beschränkten wir uns deshalb zunehmend auf Interaktion durch Bewegung. Denn wir stellten fest, dass das Dimmen oder die Farbregulierung von Licht weniger offensichtlich als Reaktion auf die Anwesenheit des Betrachters verstanden werden kann, als es bei Bewegung der Fall ist.<br />
Besonders inspirierend hierfür war das Prinzip des „Wooden Mirror“, der durch Kameraerkennung kleine flächig angeordnete Holzelemente an den Stellen anwinkelt, an denen Bewegung auftritt und somit den Eindruck eines Spiegelbildes vermittelt.</p>
<p>Unser Wunsch war es, Bewegungsabläufe im Raum nach einem ähnlichen aber weniger komplexen Prinzip auf abstrakte Weise zu reflektieren. Dies führte zu einer relativ simplen Hängung, die somit auch ein wesentlich reduzierteres Design forderte, als es für die Lichtexperimente zunächst vorgesehen gewesen war.<br />
Entstanden ist ein gliedriges, hängendes Gebilde, das auf das Verhalten des Betrachters mit kurzem Zucken reagiert.</p>
<p>Auch wenn es uns in erster Linie immer mehr um das Austesten der Möglichkeiten ging, als um das Vermitteln von Inhalten, so kann man das Ergebnis unserer Experimente auch als ironischen Kommentar zum Thema Freiheit verstehen, wenn man möchte.</p>
<p>Das Objekt mutet an wie eine moderne Marionette, die zwar den Vorgaben des Akteurs gehorcht, diese jedoch scheinbar „freiwillig“ nachahmt. Sie braucht nicht den direkten über einen Faden geleiteten Impuls, wie ihre klassischen Verwandten. Sie wirkt selbst bestimmt, ohne es zu sein, nimmt es aber mit einem (Schulter)Zucken.</p>
<h4>Technische Aspekte</h4>
<p>Die „Welle“ interagiert mit dem Betrachter über eine Webcam, die dessen Bewegungen aufzeichnet. Im Rahmen des Projektes wurde die Programmiersprache Processing, zusammen mit der OpenCV Bibliothek, zum Verarbeiten der Bildinformationen verwendet.</p>
<p>Das Bild der Webcam wird aktuell in 18 vertikale Segmente unterteilt, wobei jeder einen Bereich vor der „Welle“ darstellt. Das Erkennen einer Bewegung innerhalb eines Segments wird über das Differenzbildverfahren realisiert. Dazu wird ein vorheriges mit einem aktuellen Graustufenbild verglichen und im Falle einer Bewegung eine Differenz zwischen den einzelnen Pixelwerten errechnet. Wurden Bewegungen festgestellt, werden die betroffenen Segmente über eine Serielle Verbindung an den Arduino geschickt.</p>
<p>Die 18 Segmente werden im Arduino auf 6 Servo-Motoren aufgeteilt. Jeder Motor bekommt also 3 Seqmente zugeordnet, wobei er nur auf den Mittleren mit voller Intensität reagiert. Für die beiden äußeren Segmente wird bei der Positionsberechnung ein definierter Wert abgezogen, um einen sanfteren Übergang bei Bewegungen über mehrere Segmente zu erreichen.</p>
<p>Das Setzen der Servo-Motoren selbst kann mittels speziell definierter Variablen in beliebigen Schritten und innerhalb eines definierten Intervalls vorgenommen werden. Damit können wir den Gesamteindruck besser an die Gegebenheiten anpassen. Um dann auch bei groß eingestellten Schritten eine sanfte Bewegung zu realisieren, wird jeder Schritt nochmal in seine kleinsten Einheiten zerlegt und einzeln, nacheinander an die Servo-Motoren übertragen.</p>
<p>Da nun nach einer gewissen Zeit alle Servo-Motoren auf Bewegungen reagieren und damit Ihre Endposition einnehmen, haben wir eine Funktion geschrieben, die die Servo-Motoren bei Ereignislosigkeit wieder absenkt. Allerdings kann Ereignislosigkeit auch auftreten, wenn sich eine Person noch innerhalb der Segmente befindet. Deshalb speichern wir das Segment mit der letzten Position und senken nur die nicht betroffenen Servo-Motoren ab.</p>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>live ink crossing paperball</title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Fri, 14 Jan 2011 13:40:28 +0000</pubDate>
		<dc:creator><![CDATA[papierkugel]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=676</guid>
		<description><![CDATA[von Hannes Dieck, Urte Schwass,Aleksej Dygoduk und Roman Geez Idee In dem anfänglichen Prozess der Ideenfindung wurden mehrere Aspekte diskutiert. Jeder Projektteilnehmer brachte seine persönlichen Vorlieben aber auch individuelle Kritik hervor. Aus dieser Kreativphase entstanden mehrere Grundkonzepte. So wurden anfänglich abstrakte Modelle entwickelt, die detektierte Bewegungen farblich in Skulpturen abbilden. Der Gestaltung der Skulpturen wurde [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>von Hannes Dieck, Urte Schwass,Aleksej Dygoduk und Roman Geez</p>
<p><iframe src="http://player.vimeo.com/video/19478706" width="500" height="281" frameborder="0" title="live ink crossing paperball" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<h4>Idee</h4>
<p>In dem anfänglichen Prozess der Ideenfindung wurden mehrere Aspekte diskutiert. Jeder Projektteilnehmer brachte seine persönlichen Vorlieben aber auch individuelle Kritik hervor. Aus dieser Kreativphase entstanden mehrere Grundkonzepte. So wurden anfänglich abstrakte Modelle entwickelt, die detektierte Bewegungen farblich in Skulpturen abbilden. Der Gestaltung der Skulpturen wurde dabei bewusst keine Grenzen gesetzt. So waren Skulpturen mit klaren geometrischer Strukturen denkbar bis hin zu Objekten mit stark ausgeprägter organischer Morphologie.Im weiteren Projektverlauf wurden die Ideen konkreter und thematischer aber auch oft wieder verworfen. Themen wie die &#8220;interaktive Umkleidekabine&#8221; oder &#8220;Smash the Hedgehog&#8221; ,zu deutsch &#8220;Schlag den Igel&#8221;, wurden hervorgebracht.</p>
<p>Inspiriert durch Rohrschachbildern kam schließlich der Gedanke von verlaufenden Tintenflecken auf. Diese sollten in unserem Entwurfsmodell als Interaktions-Projektion dienen. Die Tintenflecke führten zu der Idee, den Betrachter in eine Umgebung zu führen, die  ihm die Möglichkeit aufzeigt die Tintenflecke mit seinen Aktionen so real zu manipulieren. Um die Szene räumlicher zu Gestalten wurde eine Skulptur verwendet. Diese hat die Form einer großen Papierkugel und stellt dadurch die kontextuelle Brücke zum Thema &#8220;Malen, Zeichnen und Gestalten&#8221;.</p>
<h4>Design</h4>
<p>Die Tintenflecke werden auf einer Projektionsebene dargestellt. Als Projektionsebene dient ein stehender Kreis aus weißen Sperrholzplatten. Im Vordergrund der Projektion wabert die Papierkugel, eine leuchtende (bewegende) Skulptur überzogen mit weißen halbtransparenten Stoff. Dem Betrachter könnte die Änderung der Beleuchtung der Papierkugel bei bestimmten Aktionen ins Auge fallen. Eine Überlagerung der projezierten Tintenflecke und der Papierkugel ist denkbar.</p>
<p><img class="alignnone size-full wp-image-1023" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Papierkugel_Bild1.jpg" alt="" width="267" height="400" /></p>
<p>Die Bewegungen/Aktionen werden in einem kontrollierten Bereich via Kamera aufgenommen. Als Aktionsbereich ist nur die Oberseite einer runden Säule vorgesehen. Hier befindet sich eine, aus einem Lampenschirm konstruierte, konvexe Spitze, so dass die Säule in ihrer Gesamterscheinung an einen Stift erinnern könnte. Die Oberseite wird vom inneren der Säule mit einem starken Gegenlicht ausgeleuchtet. Durch den, durch das Licht entstehenden, starken Kontrast wird die Aufnahme der Konturen von Objekten im Aktionsbereich ermöglicht. Gleichzeitig fällt dem Betrachter die Säule als Bedienelement auf. Schließlich ist es dem Betrachter durch seine Aktionen an der Säule möglich auf die projizierten Tintenflecke und die Papierkugel Einfluss zu nehmen.</p>
<p><img class="alignnone size-full wp-image-1248" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/papierkugel_design.gif" alt="" width="400" height="250" /></p>
<h4>Technische Aspekte</h4>
<p>Die Papierkugel dient als zusätzliches Ausgabemedium. Die interne Beleuchtung der Kugel wird über LED-Stripes realisiert. Diese können einzeln über Tlc&#8217;s durch einen Arduino-Microcontroller-Board angesteuert werden. Durch Kommunikation über die serielle Schnittstelle, kann die Kooperation zwischen Microcontroller-Prozess und Projektions- und Tracking-Prozess organisiert werden. Ein weiteres denkbares Feature ist die leichte Bewegung der Papierkugel-Oberfläche durch Servo-Motoren. Die Steuerung der Motoren muss ebenfalls im Microcontroller erfolgen.</p>
<p>Zur Projektion der Tintenflecke wird ein handelsüblicher PC verwendet. Die Animation wird dynamisch zur Laufzeit gerendert. Dabei erfolgt die Programmierung unter Java. Zum rendern der Tintenflecke wird die <a href="http://www.processing.org/">Processing</a>-Bibliothek verwendet. Gängige Praxis in der Simulationen von Flüssigkeiten, wie z.B. Tinte, ist der Entwurf eines Partikel-Systems. Dieser Ansatz wird auch in unserem Projekt verfolgt, wobei die Tintenflecke aus Partikeln variabler Größe bestehen. Das Partikel-System kann dabei durch die Processing Libraries <a href="http://murderandcreate.com/physics/">TRAER.PHYSICS 3.0</a> und <a href="http://www.memo.tv/msafluid_for_processing">MSAFluid</a> realisiert werden. Zur initialen Positionierung der Partikel wird ein zufälliges &#8220;perlin noise&#8221; -Fleckenbild erzeugt.</p>
<p>Zum einfachen tracken von Objekt-Konturen wird eine &#8220;definierte&#8221; Umgebung benötigt. Dazu wird ein Tracking Target von unten beleuchtet und von oben aufgenommen. Über einen umfunktionierten Lampeschirm befindet sich die sog. &#8220;Tracking Zone&#8221;. Diese wird von einem Baustrahler von unten konstant beleuchtet. Über der Tracking Zone befindet sich eine handelsübliche Webcam die den zu detektierenden Bereich aufnimmt. Durch das Gegenlicht wird ein sehr starker Kontrast vom Hintergrund (Lampenschirm) zum Tracking Object (z.B. Hand) erzielt. Die Aufnahme und Verarbeitung der einzelnen Tracking Frames erfolgt mit Hilfe der Programmbibliothek <a href="http://opencv.willowgarage.com/wiki/">OpenCV</a>. Die Programmfunktionalität für das Tracking wird in einer dynamischen Laufzeitbibliothek, die zur Nutzung via JNI optimiert ist, gekapselt. Dadurch ist ein sprachenübergreifende Kommunikation zwischen dem Animations-Subsystem (Java mit Processing) und dem Tracking-Part (C/C++ mit OpenCV) gegeben. Durch den starken Kontrast zwischen Hintergrund und Vordergrundobjekten im Bild führt ein binäres Thresholding schon fast zu der gewünschten Kontur. Die Anwendung von zusätzlichen Kantenfiltern wie Canny-Edge können die Konturen weiterhin verstärken. Nach erfolgter binarisierung werden zur Einfachheit der Segmentierung alle zusammenhängenden Objekte als eins betrachtet. Die blob detection library <a href="http://opencv.willowgarage.com/wiki/cvBlobsLib">cvBlobsLib</a> übernimmt dies. Als Ergebnis des Tracking-Vorgangs werden Deskriptoren gespeichert (Fourier oder Momente), die die Beschaffenheit der Objekte beschreiben. Diese können über die JNI-Schnitstelle ausgelesen werden. Schließlich erfolgt die Reaktion abhängig von den erkannten Objekten im Animationsprozess.</p>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Vorarbeit</title>
		<link>http://computationalspaces.org/reactive-landscapes/</link>
		<comments>http://computationalspaces.org/reactive-landscapes/#comments</comments>
		<pubDate>Sat, 01 Jan 2011 22:37:36 +0000</pubDate>
		<dc:creator><![CDATA[csadmin]]></dc:creator>
				<category><![CDATA[reactive landscapes]]></category>

		<guid isPermaLink="false">http://adriane.lol-hamburg.de/?p=994</guid>
		<description><![CDATA[von Janina Schlichte, Simon Alt, Prof. Birgit Wendholt und Prof. Franziska Hübler Modul 1: Bewegungserkennung Modul 2: Farberkennung Modul 3: Bewegungsintensität]]></description>
				<content:encoded><![CDATA[<p>von Janina Schlichte, Simon Alt, Prof. Birgit Wendholt und<br />
Prof. Franziska Hübler</p>
<p><iframe src="http://player.vimeo.com/video/19411807" width="500" height="281" frameborder="0" title="basic examples" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<p>Modul 1: Bewegungserkennung</p>
<p><img class="alignnone size-full wp-image-1013" title="Vor_Vorarbeit1" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Vor_Vorarbeit1.jpg" alt="" width="400" height="267" /></p>
<p><img class="alignnone size-full wp-image-1014" title="Vor_Vorarbeit2" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Vor_Vorarbeit2.jpg" alt="" width="400" height="267" /></p>
<p>Modul 2: Farberkennung</p>
<p><img class="alignnone size-full wp-image-1017" title="Vor_Vorarbeit3" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Vor_Vorarbeit3.jpg" alt="" width="400" height="267" /></p>
<p><img class="alignnone size-full wp-image-1018" title="Vor_Vorarbeit4" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Vor_Vorarbeit4.jpg" alt="" width="267" height="400" /></p>
<p>Modul 3: Bewegungsintensität</p>
<p><img class="alignnone size-full wp-image-1020" title="Vor_Vorarbeit5" src="http://v23.informatik.haw-hamburg.de/wp-content/uploads/Vor_Vorarbeit5.jpg" alt="" width="267" height="400" /></p>
]]></content:encoded>
			<wfw:commentRss>http://computationalspaces.org/reactive-landscapes/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
